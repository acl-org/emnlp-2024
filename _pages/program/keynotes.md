---
title: Main Conference Keynotes 
layout: single
excerpt: "EMNLP 2024 Keynote Speakers."
permalink: /program/keynotes/
toc: true
toc_sticky: true
toc_icon: "cog"
sidebar: 
    nav: program
---

We are delighted to announce that the esteemed speakers listed below have graciously accepted our invitation to deliver keynote speeches at the main conference of EMNLP 2024:

<style>
p.speaker-bio { font-style: italic; font-size: 80%; }
</style>

## Tuesday, November 12, James Knight Center, Time: 09:30 - 10:30: [Percy Liang](https://cs.stanford.edu/~pliang/bio.txt)

![Gary Marcus](/assets/images/keynotes/Percy_Liang.jpg){: .align-center}


### Open-Source and Science in the Era of Foundation Models

As capabilities of foundation models skyrocket, openness plummets. In this talk, I argue that open-source models are essential for the long-term goal of building a rigorous foundation for AI. Greater access---from API to open-weight to open-source---enables deeper forms of research.  API access allows us to push the frontier of agents, and I will present our recent work on simulation and problem-solving agents. Open weights enables reproducible research on safety, interpretability, and more generally, “model forensics”. Open-source unlocks fundamental innovations in architectures, training procedures, and data curation methods. Of course, the key obstacle for building open-source models is the resources required (data, compute, and research/engineering). I will conclude with some promising directions that leverage the community that bring us closer to the vision of open-source foundation models. 
{: .speaker-bio}

## Wednesday, November 13, James Knight Center, Time: 09:00 - 10:00: [Anca Dragan](https://www2.eecs.berkeley.edu/Faculty/Homepages/anca.html)

![Neil Cohn](/assets/images/keynotes/Anca_Dragan.jpg){: .align-center}

### My Journey in AI Safety and Alignment


For nearly a decade now, the problem that has been top of mind for me is how we might enable AI systems to robustly optimize for what people want, and to avoid causing harm – from robots and self-driving cars, to assistive devices and deep brain stimulation, to theory and toy models, to large language models and now Gemini. In this talk, I’ll take the opportunity to share a bit about my journey in this space, what lessons I’ve learned, and how we’re approaching the safety and alignment of frontier 
models at Google DeepMind.
{: .speaker-bio}

## Thursday, November 14, James Knight Center, Time: 09:00 - 10:00: [Tom Griffiths](https://cocosci.princeton.edu/tom/index.php)

![Mona Diab](/assets/images/keynotes/Tom_Griffiths.jpg){: .align-center}

### Bayes in the age of intelligent machines


Recent rapid progress in the creation of artificial intelligence (AI) systems has been driven in large part by innovations in architectures and algorithms for developing large scale artificial neural networks. As a consequence, it’s natural to ask what role abstract principles of intelligence — such as Bayes’ rule — might play in developing intelligent machines. In this talk, I will argue that there is a new way in which Bayes can be used in the context of AI, more akin to how it is used in cognitive science: providing an abstract description of how agents should solve certain problems and hence a tool for understanding their behavior. This new role is motivated in large part by the fact that we have succeeded in creating intelligent systems that we do not fully understand, making the problem for the machine learning researcher more closely parallel that of the cognitive scientist. I will talk about how this perspective can help us think about making machines with better informed priors about the world and give us insight into their behavior by directly creating cognitive models of neural networks.
{: .speaker-bio}



